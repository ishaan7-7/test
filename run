# File: C:\streaming_emulator\writer_service\src\infrastructure.py
import os
import sys
from pathlib import Path

def setup_environment():
    """
    Sets up the portable environment variables for Spark on Windows.
    Aggressively overrides system defaults to ensure version consistency.
    """
    print("üîß Initializing Portable Spark Infrastructure...")

    # 1. Locate Project Root
    current_dir = Path(__file__).parent.absolute()
    project_root = None
    for parent in [current_dir] + list(current_dir.parents):
        if parent.name == "streaming_emulator":
            project_root = parent
            break
    if not project_root:
        project_root = Path(r"C:\streaming_emulator")

    # 2. Define Critical Paths
    tools_dir = project_root / "tools"
    jdk_path = Path(r"C:\jdk-11.0.28+6")
    hadoop_home = tools_dir / "hadoop"
    hadoop_bin = hadoop_home / "bin"

    # 3. Validation
    if not jdk_path.exists():
        print(f"‚ùå STOP: JDK not found at {jdk_path}")
        sys.exit(1)
    if not (hadoop_bin / "winutils.exe").exists():
        print(f"‚ùå STOP: winutils.exe not found at {hadoop_bin}")
        sys.exit(1)

    # 4. OVERRIDE: Spark Home (The Fix for your Crash)
    # We must force Python to use the Spark libraries inside the .venv, 
    # ignoring any global Spark installation.
    try:
        import pyspark
        venv_spark_home = Path(pyspark.__path__[0])
        os.environ['SPARK_HOME'] = str(venv_spark_home)
        print(f"‚úÖ Forced SPARK_HOME to .venv: {venv_spark_home}")
    except ImportError:
        print("‚ùå Could not import pyspark to find its location.")
        sys.exit(1)

    # 5. Inject Environment Variables
    # Unset conflicting variables if they exist
    if 'PYTHONPATH' in os.environ:
        del os.environ['PYTHONPATH']
        
    os.environ['JAVA_HOME'] = str(jdk_path)
    os.environ['HADOOP_HOME'] = str(hadoop_home)
    
    # 6. Update System Path
    # Prepend JDK and Hadoop to PATH
    current_path = os.environ.get('PATH', '')
    new_paths = [
        str(jdk_path / "bin"),
        str(hadoop_bin)
    ]
    os.environ['PATH'] = ";".join(new_paths) + ";" + current_path

    print(f"‚úÖ JAVA_HOME set to: {os.environ['JAVA_HOME']}")
    print(f"‚úÖ HADOOP_HOME set to: {os.environ['HADOOP_HOME']}")
    print("‚úÖ Infrastructure Ready.\n")

if __name__ == "__main__":
    setup_environment()
