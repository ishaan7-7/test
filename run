# File: C:\streaming_emulator\writer_service\verify_step1.py
import sys
from pathlib import Path

# Add 'src' to python path so we can import infrastructure
src_path = Path(__file__).parent / "src"
sys.path.append(str(src_path))

# 1. Run Infrastructure Setup
try:
    import infrastructure
    infrastructure.setup_environment()
except ImportError as e:
    print(f"❌ CRITICAL: Could not import infrastructure module. Check file placement. Error: {e}")
    sys.exit(1)
except SystemExit:
    print("❌ Verification Failed during Infrastructure Setup.")
    sys.exit(1)

# 2. Test PySpark Import (This usually fails if Java/Hadoop are wrong)
print("⏳ Attempting to import PySpark...")
try:
    from pyspark.sql import SparkSession
    print("✅ PySpark imported successfully.")
except ImportError as e:
    print(f"❌ Failed to import PySpark. Is it installed in .venv? Error: {e}")
    sys.exit(1)

# 3. Test Session Creation (The ultimate test for winutils)
print("⏳ Attempting to start a Spark Session (Local Mode)...")
try:
    spark = SparkSession.builder \
        .appName("InfrastructureVerification") \
        .master("local[*]") \
        .getOrCreate()
    
    print("✅ SparkSession created successfully!")
    print(f"   Spark Version: {spark.version}")
    
    # Simple calculation to prove JVM is working
    data = [("Java", 1), ("Python", 2)]
    df = spark.createDataFrame(data, ["Language", "ID"])
    count = df.count()
    print(f"   Test DataFrame Count: {count}")
    
    spark.stop()
    print("✅ Verification Complete. Infrastructure is robust.")

except Exception as e:
    print(f"\n❌ SPARK CRASHED: {e}")
    print("Possible causes:")
    print("1. JAVA_HOME path is incorrect.")
    print("2. winutils.exe or hadoop.dll are missing or blocked by antivirus.")
    print("3. Python version mismatch.")
