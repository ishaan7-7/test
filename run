# File: C:\streaming_emulator\writer_service\src\infrastructure.py
import os
import sys
from pathlib import Path

def setup_environment():
    """
    Sets up the portable environment variables for Spark on Windows.
    Must be called BEFORE importing pyspark.
    """
    print("üîß Initializing Portable Spark Infrastructure...")

    # 1. Define Paths
    # We assume this script is in writer_service/src/
    # So project_root is two levels up from writer_service
    # Adjust logic: We know we are in C:\streaming_emulator\...
    # Let's find the root 'streaming_emulator' directory
    current_dir = Path(__file__).parent.absolute()
    
    # Traverse up until we find 'streaming_emulator' or hit root
    project_root = None
    for parent in [current_dir] + list(current_dir.parents):
        if parent.name == "streaming_emulator":
            project_root = parent
            break
            
    if not project_root:
        # Fallback for testing execution
        project_root = Path(r"C:\streaming_emulator")

    tools_dir = project_root / "tools"
    jdk_path = Path(r"C:\jdk-11.0.28+6")
    hadoop_home = tools_dir / "hadoop"
    hadoop_bin = hadoop_home / "bin"

    # 2. Validation
    errors = []
    if not jdk_path.exists():
        errors.append(f"‚ùå JDK not found at: {jdk_path}")
    
    if not (hadoop_bin / "winutils.exe").exists():
        errors.append(f"‚ùå winutils.exe not found at: {hadoop_bin}")

    if not (hadoop_bin / "hadoop.dll").exists():
        errors.append(f"‚ùå hadoop.dll not found at: {hadoop_bin}")

    if errors:
        print("\n".join(errors))
        print("STOPPING: Please fix the missing dependencies.")
        sys.exit(1)

    # 3. Inject Environment Variables
    # Spark needs these to be set in os.environ
    os.environ['JAVA_HOME'] = str(jdk_path)
    os.environ['HADOOP_HOME'] = str(hadoop_home)
    
    # 4. Update System Path
    # We must prepend these to PATH so Windows finds the .dll and .exe
    current_path = os.environ.get('PATH', '')
    
    # Construct new path entries
    new_paths = [
        str(jdk_path / "bin"),
        str(hadoop_bin)
    ]
    
    # Prepend to PATH
    os.environ['PATH'] = ";".join(new_paths) + ";" + current_path

    print(f"‚úÖ JAVA_HOME set to: {os.environ['JAVA_HOME']}")
    print(f"‚úÖ HADOOP_HOME set to: {os.environ['HADOOP_HOME']}")
    print("‚úÖ Infrastructure Ready.\n")

if __name__ == "__main__":
    # Allow running this script directly to test paths
    setup_environment()
