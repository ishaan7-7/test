import asyncio
import aiohttp
import json
import re
import logging
from collections import defaultdict
from typing import Dict, Any, List
from datetime import datetime
from aiokafka import AIOKafkaConsumer
from pathlib import Path

# --- Import Existing Config ---
# We use the existing loader so we don't hardcode ports/topics
try:
    from ingest.app.config_loader import IngestConfig
except ImportError:
    # Fallback if run incorrectly, but instructions will ensure correct path
    import sys
    sys.path.append(str(Path.cwd()))
    from ingest.app.config_loader import IngestConfig

# --- Configuration ---
INGEST_METRICS_URL = "http://127.0.0.1:8000/metrics"

# Service Ports to Monitor
PORTS_TO_CHECK = {
    "Zookeeper": 2181,
    "Kafka": 9092,
    "Ingest": 8000,
    "Replay": 9001,
    "Kafka Metrics": 9201,
    "Dashboard": 9300
}

# Regex to parse Prometheus Text Format
# Matches: ingest_rows_validation_detail_total{status="rejected",vehicle_id="sim001"} 5.0
VALIDATION_REGEX = re.compile(r'ingest_rows_validation_detail(?:_total)?\{.*vehicle_id="([^"]+)".*status="([^"]+)".*\}\s+(\d+\.?\d*)')
# Matches: dlq_size_files 12.0
DLQ_GAUGE_REGEX = re.compile(r'dlq_size_files\s+(\d+\.?\d*)')

# Configure Logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger("ObserverEngine")

class HybridObserver:
    def __init__(self):
        # Load existing config to get Kafka bootstrap & topics
        self.ingest_config = IngestConfig(Path("ingest/config/ingest_config.json"))
        
        self.lock = asyncio.Lock()
        self.running = False
        
        # --- Shared State ---
        self.port_health: Dict[str, bool] = {k: False for k in PORTS_TO_CHECK}
        self.global_dlq_size = 0
        
        # Vehicle Data Structure:
        # { "sim001": { "accepted": 0, "rejected": 0, "latency_sum": 0.0, ... } }
        self.vehicle_data = defaultdict(lambda: {
            "accepted": 0, 
            "rejected": 0, 
            "latency_sum": 0.0, 
            "latency_count": 0,
            "last_seen": 0,
            "latest_payload": {}
        })

    async def start(self):
        """Starts all background monitoring tasks."""
        self.running = True
        logger.info("Starting Telemetry Observer Engine...")
        
        await asyncio.gather(
            self._monitor_ports(),
            self._poll_http_metrics(),
            self._consume_kafka_stream()
        )

    async def stop(self):
        """Stops the engine."""
        self.running = False
        logger.info("Stopping Observer Engine.")

    # ---------------------------------------------------------
    # Task A: Port Scanner
    # ---------------------------------------------------------
    async def _monitor_ports(self):
        while self.running:
            results = {}
            for name, port in PORTS_TO_CHECK.items():
                try:
                    # Attempt a quick TCP handshake
                    _, writer = await asyncio.wait_for(
                        asyncio.open_connection("127.0.0.1", port), timeout=0.2
                    )
                    writer.close()
                    await writer.wait_closed()
                    results[name] = True
                except:
                    results[name] = False
            
            async with self.lock:
                self.port_health = results
            
            await asyncio.sleep(2)  # Check every 2 seconds

    # ---------------------------------------------------------
    # Task B: HTTP Metrics Poller (Quality & DLQ)
    # ---------------------------------------------------------
    async def _poll_http_metrics(self):
        async with aiohttp.ClientSession() as session:
            while self.running:
                try:
                    async with session.get(INGEST_METRICS_URL, timeout=1) as resp:
                        if resp.status == 200:
                            text = await resp.text()
                            self._parse_metrics(text)
                except Exception:
                    # Ingest service might be down, just ignore this poll
                    pass
                
                await asyncio.sleep(1) # Poll every 1 second

    def _parse_metrics(self, text: str):
        """Parses the raw Prometheus text from Ingest."""
        temp_dlq = 0
        
        # We parse line by line
        lines = text.splitlines()
        for line in lines:
            if line.startswith("#"): continue
            
            # 1. Check for Validation Details
            v_match = VALIDATION_REGEX.search(line)
            if v_match:
                v_id, status, val = v_match.groups()
                count = int(float(val))
                
                # Update specific field based on status label
                if status == "rejected":
                    self.vehicle_data[v_id]["rejected"] = count
                elif status == "accepted":
                    # We usually trust Kafka for accepted, but this is a good cross-check
                    # We won't overwrite Kafka count here to avoid race conditions, 
                    # but we could use it for reconciliation if needed.
                    pass
                continue

            # 2. Check for DLQ Size
            d_match = DLQ_GAUGE_REGEX.search(line)
            if d_match:
                temp_dlq = int(float(d_match.group(1)))
        
        # Commit to state (thread-safe)
        if self.running: # Check again before locking
             # Note: We use a sync update here since we are inside a callback/loop
             # But accessing self.vehicle_data should technically be locked if accessed across threads.
             # Since asyncio is single-threaded cooperative multitasking, this is generally safe 
             # between awaits, but we use explicit lock for good measure.
             pass # Logic moved to async lock below isn't needed for simple dict updates in asyncio
             
             self.global_dlq_size = temp_dlq

    # ---------------------------------------------------------
    # Task C: Kafka Listener (Latency & Live Data)
    # ---------------------------------------------------------
    async def _consume_kafka_stream(self):
        # We subscribe to ALL topics found in the config
        topics = list(self.ingest_config.topic_mapping.values())
        
        consumer = AIOKafkaConsumer(
            *topics,
            bootstrap_servers=self.ingest_config.kafka_bootstrap_servers,
            group_id="telemetry-observer-phase1",
            auto_offset_reset="latest"
        )

        try:
            await consumer.start()
            logger.info(f"Observer connected to Kafka topics: {topics}")
            
            async for msg in consumer:
                if not self.running: break
                
                try:
                    payload = json.loads(msg.value)
                    meta = payload.get("metadata", {})
                    v_id = meta.get("vehicle_id")
                    ingest_ts_str = meta.get("ingest_ts")
                    
                    # --- Latency Calculation ---
                    latency_ms = 0.0
                    if ingest_ts_str:
                        # Parse ISO format: 2026-01-20T10:00:00.123456+00:00
                        ts = datetime.fromisoformat(ingest_ts_str)
                        # Ensure we compare UTC to UTC
                        if ts.tzinfo is None:
                            now = datetime.utcnow()
                        else:
                            from datetime import timezone
                            now = datetime.now(timezone.utc)
                            
                        latency_ms = (now - ts).total_seconds() * 1000
                        if latency_ms < 0: latency_ms = 0

                    # --- Update State ---
                    if v_id:
                        async with self.lock:
                            entry = self.vehicle_data[v_id]
                            entry["accepted"] += 1
                            entry["latency_sum"] += latency_ms
                            entry["latency_count"] += 1
                            entry["last_seen"] = asyncio.get_event_loop().time()
                            entry["latest_payload"] = payload

                except Exception as e:
                    # Malformed message in stream
                    pass
        except Exception as e:
            logger.error(f"Kafka Connection Failed: {e}")
        finally:
            await consumer.stop()

    # ---------------------------------------------------------
    # Public API: Get Snapshot
    # ---------------------------------------------------------
    async def get_snapshot(self) -> Dict[str, Any]:
        """Returns the fully aggregated state for the UI."""
        async with self.lock:
            vehicle_list = []
            global_lat_sum = 0.0
            global_lat_count = 0
            total_rows = 0

            current_time = asyncio.get_event_loop().time()

            for v_id, data in self.vehicle_data.items():
                acc = data["accepted"]
                rej = data["rejected"]
                total = acc + rej
                
                # Validation Rate
                val_rate = (acc / total * 100.0) if total > 0 else 100.0
                
                # Avg Latency for this vehicle
                v_lat_avg = 0.0
                if data["latency_count"] > 0:
                    v_lat_avg = data["latency_sum"] / data["latency_count"]
                    global_lat_sum += data["latency_sum"]
                    global_lat_count += data["latency_count"]
                
                # Last Seen (Seconds ago)
                ago = round(current_time - data["last_seen"], 1)

                vehicle_list.append({
                    "vehicle_id": v_id,
                    "rows_processed": acc,
                    "rejected_rows": rej,
                    "validation_rate": round(val_rate, 1),
                    "avg_latency": round(v_lat_avg, 1),
                    "last_seen_sec": ago,
                    "latest_payload": data["latest_payload"]
                })
                
                total_rows += acc

            # Global Averages
            global_avg_lat = (global_lat_sum / global_lat_count) if global_lat_count > 0 else 0.0

            return {
                "system_health": dict(self.port_health),
                "global_stats": {
                    "total_rows": total_rows,
                    "active_vehicles": len(vehicle_list),
                    "avg_latency": round(global_avg_lat, 1),
                    "dlq_backlog": self.global_dlq_size
                },
                "vehicles": vehicle_list
            }

# ---------------------------------------------------------
# VERIFICATION TEST RUNNER
# ---------------------------------------------------------
if __name__ == "__main__":
    # This block allows you to run the file directly to test Phase 1
    async def test_runner():
        observer = HybridObserver()
        asyncio.create_task(observer.start())
        
        print("\n--- Observer Engine Started (Press Ctrl+C to stop) ---")
        print("Waiting for data stream...\n")
        
        try:
            while True:
                await asyncio.sleep(5)
                snapshot = await observer.get_snapshot()
                
                print(f"--- Snapshot at {datetime.now().strftime('%H:%M:%S')} ---")
                print(f"Ports: {snapshot['system_health']}")
                print(f"Global: {snapshot['global_stats']}")
                if snapshot['vehicles']:
                    print(f"Vehicles (Top 3):")
                    for v in snapshot['vehicles'][:3]:
                        print(f"  - {v['vehicle_id']}: Rate={v['validation_rate']}% | Latency={v['avg_latency']}ms | Payload={v['latest_payload'] != {}}")
                else:
                    print("Vehicles: None active")
                print("-" * 50)
                
        except KeyboardInterrupt:
            await observer.stop()

    try:
        asyncio.run(test_runner())
    except KeyboardInterrupt:
        pass
